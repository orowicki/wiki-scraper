{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ce326b",
   "metadata": {},
   "source": [
    "# Analiza skuteczności funkcji wykrywającej język"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b12c31",
   "metadata": {},
   "source": [
    "## Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordfreq import top_n_list, word_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10392a",
   "metadata": {},
   "source": [
    "## Ładujemy przygotowane dane o tekstach/artykułach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee3175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_files = {\n",
    "    \"Wiki długi\": \"word_counts/long_article/word-counts.json\",\n",
    "    \"Wiki słaby\": \"word_counts/bad_article/word-counts.json\",\n",
    "    \"Moby Dick (angielski)\": \"word_counts/english/word-counts.json\",\n",
    "    \"Książe (polski)\": \"word_counts/polish/word-counts.json\",\n",
    "    \"Vida De Lazarillo.. (hiszpański)\": \"word_counts/spanish/word-counts.json\",\n",
    "}\n",
    "\n",
    "word_counts_data = {}\n",
    "for name, path in word_count_files.items():\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        word_counts_data[name] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f93f6a",
   "metadata": {},
   "source": [
    "## Przygotowujemy dane o językach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {\n",
    "    \"angielski\": (\"en\", top_n_list(\"en\", 1000, wordlist=\"large\")),\n",
    "    \"polski\": (\"pl\", top_n_list(\"pl\", 1000, wordlist=\"large\")),\n",
    "    \"hiszpański\": (\"es\", top_n_list(\"es\", 1000, wordlist=\"large\")),\n",
    "}\n",
    "\n",
    "languages_with_word_frequencies = {}\n",
    "for lang, (code, words) in languages.items():\n",
    "    languages_with_word_frequencies[lang] = {\n",
    "        w: word_frequency(w, code) for w in words\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88266de3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Definicja funkcji określania pewności co do języka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be1286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_confidence_score(\n",
    "    word_counts: dict[str, int], lang_words_with_freq: dict[str, int]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute a language confidence score for a text.\n",
    "\n",
    "    Higher score = better match with the language.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    word_counts: dict[word -> count]\n",
    "    lang_words_with_freq: dict[word -> frequency]\n",
    "    \"\"\"\n",
    "    max_freq = max(lang_words_with_freq.values())\n",
    "    words_with_normalized_freq = {\n",
    "        w: freq / max_freq for w, freq in lang_words_with_freq.items()\n",
    "    }\n",
    "\n",
    "    score = 0.0\n",
    "    for word, count in word_counts.items():\n",
    "        frequency = words_with_normalized_freq.get(word, 0)\n",
    "        score += frequency * count\n",
    "\n",
    "    score /= sum(word_counts.values())\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca6673",
   "metadata": {},
   "source": [
    "## Liczymy wyniki dla 3, 10, 100, 1000 najczęstszych słów w językach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [3, 10, 100, 1000]\n",
    "results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    results[k] = {}\n",
    "    for lang, frequencies in languages_with_word_frequencies.items():\n",
    "        topk = {\n",
    "            w: freq for r, (w, freq) in enumerate(frequencies.items()) if r < k\n",
    "        }\n",
    "        scores = {}\n",
    "        for text_name, wc in word_counts_data.items():\n",
    "            scores[text_name] = lang_confidence_score(wc, topk)\n",
    "        results[k][lang] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e287f0",
   "metadata": {},
   "source": [
    "## Rysujemy wykresy dla wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257aff6b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "texts = list(word_counts_data.keys())\n",
    "for k in k_values:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for lang in languages.keys():\n",
    "        y = [results[k][lang][txt] for txt in texts]\n",
    "        plt.plot(texts, y, marker=\"o\", label=lang)\n",
    "    plt.title(f\"Wynik pewności języka dla {k} najczęstszych słów\")\n",
    "    plt.xlabel(\"Tekst / Artykuł\")\n",
    "    plt.ylabel(\"Wynik\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee81259",
   "metadata": {},
   "source": [
    "\n",
    "## Analiza wyników\n",
    "\n",
    "Funkcja `lang_confidence_score` jest dość skuteczna.\n",
    "Dla każdej ze sprawdzanych wielkości `k`, wynik dla języka źródłowego\n",
    "był znacznie większy od wyników dla innych języków.\n",
    "\n",
    "Podczas, gdy różnica wyników dla `k = 3` i `k = 10` jest duża,\n",
    "wraz ze wzrostem `k`, różnica między wynikami szybko maleje -\n",
    "wykresy dla `k = 100` i `k = 1000` są niemal takie same.\n",
    "Jest to najprawdopodobniej spowodowane heurystyką przedstawionej\n",
    "funkcji, która licząc wynik silnie faworyzuje te słowa, które\n",
    "występują najczęściej, zatem ignorowanie rzadziej występujących słów\n",
    "nie ma dużego wpływu na wynik.\n",
    "\n",
    "Maksymalny wynik, który może zwrócić `lang_confidence_score` to `1.0`,\n",
    "ale przedstawione wyniki nie przekraczają `0.16`. Jest tak dlatego, że\n",
    "wynik `1.0` jest możliwy tylko dla tekstów składających się całkowicie\n",
    "z najczęstszego słowa w danym języku. Z tych powodów możliwe, że\n",
    "dla analizy realistycznych tekstów warto by było normalizować jakoś\n",
    "wynik, np. dzieląc przez `0.18`, i odczytując go jako `%` pewności.\n",
    "\n",
    "Dobór języków miał znaczenie. Dla języka polskiego funkcja zadziałała\n",
    "najgorzej, podczas gdy dla hiszpańskiego najlepiej.\n",
    "Można z tego wywnioskować, że funkcja prawdopodobnie działa lepiej\n",
    "dla języków mniej fleksyjnych + o bardziej ustalonym szyku zdania.\n",
    "\n",
    "Ponieważ funkcja daje niższy wynik dla bardziej fleksyjnych języków,\n",
    "możnaby zastosować heurystykę, że niższy wynik dla języka i tekstu\n",
    "w nim napisanego, względem takich wyników innych języków, oznacza, że\n",
    "w danym języku słowa są częściej odmieniane.\n",
    "\n",
    "Znalezienie artykułu, który daje słaby wynik nie było trudne.\n",
    "Celowałem w stosunkowo krótki artykuł o rzeczy nieistniejącej\n",
    "w języku angielskim. Wygrał `Netherite_sword`, w którego\n",
    "artykule często występują słowa \"netherite\"\n",
    "(które nie istnieje w angielskim) oraz \"sword\"\n",
    "(które raczej nie jest częstym słowem w angielskim).\n",
    "Gdyby wybrane wiki nie było o grze wideo, możliwe, że nie istniałby\n",
    "artykuł pełny fikcyjnego słowa."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
